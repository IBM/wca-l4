{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) introduces IBM watsonx Code Assistant's generative AI capabilities and lays the groundwork for the hands-on training that will follow. [6 min] i. Automation is indispensable to modern IT strategy Despite the innovations and advancements made in the domain of automation, IBM sellers and partners know first-hand from discussions with clients that many businesses are still struggling to keep up with their IT operations. The rapid pace of technological innovation\u2014 in particular, areas such as AI and machine learning \u2014are obviously challenging for any organization to strategize and plan around. But smaller, more practical challenges also stand in the way of these businesses. The fact remains that IT operations, and wrangling those operations in an efficient and streamlined manner, remains a difficult problem to solve. Three primary pain points that IBM consistently hears from the marketplace include: an ever-increasing skills gap in IT management; that Day 2 operations continue to be labor-intensive, mostly manual endeavors; and that the complexity of the systems needing to be managed are out-pacing many organization\u2019s ability to adapt. All of these pain points are potential automation challenges to be solved. Each of them impedes a company's ability to move quickly and adapt for the future. And as such, for many IBM clients, solving these automation challenges have become an indispensable element in their strategy to modernize IT. UNPRECEDENTED RATE OF GENERATIVE AI ADOPTION Even though generative AI is relatively new, the widespread popularity of ChatGPT has created significant interest in the notion of large language models (LLMs) and foundation models (FMs) \u2014 and what they can do for business. It took quite some time for enterprises to start moving toward traditional AI. In contrast, generative AI has experienced massive early adoption: 80% of enterprises are already working with, or planning to leverage FMs, and plan to adopt generative AI in their use cases and workflow. Moreover, the following data points to an ever-growing adoption trend for generative AI: Scale Zeitgeist 2023 AI Readiness Report notes that with the companies they reviewed, 21% have generative AI models in production; 29% are experimenting with generative AI and another 31% are planning to work with generative AI models; a total of 81% are either working with or planning to work with generative AI models Goldman Sachs has estimated that generative AI will have a very deep economic impact \u2013 raising global Gross Domestic Product (GDP) by 7% within 10 years, reflecting the technology\u2019s huge potential. Boston Consulting Group (BCG) noted that generative AI is expected to represent 30% of the overall market by 2025 ii. Generative AI-assisted code lifecycle management achieves what LLMs alone cannot Following the debut of OpenAI's ChatGPT, the marketplace has been awash with competing large language model (LLM) and generative AI-based assistants. It's one thing to train and deploy an LLM; it's another thing entirely to make it applicable and tangibly beneficial for business. What separates IBM watsonx Code Assistant (WCA) offerings from competing vendors in the marketplace? The design and implementation of WCA is purposely built to assist, using generative AI, software and code lifecycle management. In short, generative AI-assisted code lifecycle management helps to achieve what large language models cannot achieve on their own. It is what distinguished WCA from other code assistants in the marketplace today. Code lifecycle management begins with understanding client code, through training across a myriad of programming languages and specializations in paradigms such as Ansible Automation Platform, and applies that understanding across a client\u2019s application and runtime environments. Users are able to plan next steps based on generative AI analysis of their existing application code. Operations teams can rapidly transform their codebases with optimized design and architecture that is recommended according to IBM Granite's best-practice models. Administrators can validate the outcomes with automatically generated unit tests. Afterwards, they can deploy those services and applications using automated processes like Ansible's automation engine. Over the course of that application or code's lifecycle, generative AI can maintain healthy operations with runtime insights. iii. Introducing the IBM watsonx Code Assistant product family IBM watsonx Code Assistant is the flagship offering in a suite of generative AI code assistant products, which also include offerings for Ansible Automation Platform (IBM watsonx Code Assistant for Red Hat Ansible Lightspeed) and IBM Systems modernization (IBM watsonx Code Assistant for Z). These solutions accelerate software development tasks with AI-powered capabilities including context-aware code generation, explanation, documentation, translation, and unit test generation. It does so while maintaining the principles of trust, security, and compliance with regards to IBM client's data and intellectual property. Developers and IT Operators can utilize WCA to speed up application modernization efforts and generate Ansible-based automation jobs to rapidly scale out (or scale up) IT environments. IBM watsonx Code Assistant products are powered by IBM Granite foundation models that include state-of-the-art large language models designed for code. For offerings such as WCA for Ansible Lightspeed and WCA for Z, bespoke code models\u2014 tailored to working with Ansible Automation Platform and COBOL-to-Z use cases, respectively \u2014are invoked. Universally true for all of the watsonx Code Assistant offerings is that they are geared towards helping IT teams create high-quality code using AI-generated recommendations, based on natural language requests or existing source code. These AI models, and the recommendations they generate, are seamlessly integrated via extensions with the world's most popular developer integrated development environments (IDE), including Visual Studio Code and Eclipse. Granite is IBM\u2019s flagship brand of open and proprietary LLMs, spanning multiple modalities. Granite models exist for code, languages, time series, and GeoSpatial \u2014 with additional modalities expected in future. IBM Granite code models are a series of decoder-only models for code generative tasks, trained with code written in 116 different programming languages. The Granite code models family consists of models ranging in size from 3 to 34 billion parameters, in both a base model and instruction-following model variants. These models have a range of uses, from complex application modernization tasks to on-device memory-constrained use cases. The larger the block size for a particular language on this chart, the larger percentage of training corpus data of that language was used to train the Granite code model. Languages and formats such as Java, C, JSON, JavaScript, HTML, and PHP are subjects in which the model \u201cMajors\u201d and excels. Other languages such as Ruby, SQL, and Swift could be considered \u201cMinors\u201d where the generalized code model can work with the language, but has less training data to base those recommendations on. These percentages and training data volumes will continue to evolve as the Granite code models mature. WATSONX CODE ASSISTANT vs. WCA FOR ANSIBLE LIGHTSPEED? For those familiar with other IBM watsonx Code Assistant offerings\u2014 such as WCA for Red Hat Ansible Lightspeed and WCA for Z \u2014the generalized code model approach, as seen here, differs from the specialized code model approach of those two aforementioned offerings. The WCA for Ansible Lightspeed flavor of IBM Granite code models specializes (Majors) only in Ansible Playbooks and YAML Similarly, the IBM Granite code model used by WCA for Z specializes in transforming COBOL mainframe code into modernized Java code Ansible Playbooks (YAML) and mainframe (COBOL) code are both supported (Minor) languages for the generalized IBM Granite code models\u2014 and therefore are supported by IBM watsonx Code Assistant \u2014but if a client wishes to specialize in those particular languages and frameworks, they would be well advised to utilize the bespoke WCA for Ansible Lightspeed and WCA for Z offerings, respectively, to do so. iv. Solution architecture of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed IBM watsonx Code Assistant for Red Hat Ansible Lightspeed meets developers where they are: with a rich plugin via VS Code extensions, where developers input their prompts directly in the code editor. Prompts are sent to the Ansible Lightspeed service, and the service sends a suggestion back (a completion ) that\u2019s powered by IBM Granite LLMs for code. It is important to note that all data in transit is encrypted and ephemeral so users can be confident and have trust in the security of the service during this exchange. In terms of data security, client Ansible playbooks and customized models that they may potentially have are stored in client-owned Cloud Object Storage and are not shared with IBM, Red Hat, or any other clients. In order to utilize IBM watsonx Code Assistant for Red Hat Ansible Lightspeed, a client must have an existing license for Red Hat Ansible Automation Platform (the \u201dred tile\u201d component in the center of the diagram), as well as a license for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed (the \u201cblue tile\u201d on the right of the diagram). Generative AI has recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. For example, if trained on a large dataset of Ansible Playbooks, generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. WHAT ARE PLAYBOOKS? Ansible Playbooks instruct Ansible\u2019s automation engine on how to execute tasks in a step-by-step manner. Playbooks defines roles, tasks, handlers, and other configurations; in turn, these attributes allow developers and users to codify complex orchestration scenarios. Conceptually, think of a Playbook as a recipe book for system administration: each recipe (or Playbook) spells out the steps required to achieve a particular system state or to complete a given operation. One of the standout features of Ansible Playbooks is that they are idempotent : executing Playbooks multiple times on the same system won't create additional \"side effects\" (unintended operations or creation of unwanted artifacts) after the first successful run. This ensures consistency and reliability across deployments of the Red Hat Ansible Automation Platform ( AAP ). As you will see throughout the hands-on training material, generative AI models provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language ( \"I want a Playbook to install and start an Apache web server\" ) and the model will generate the appropriate Ansible Tasks for a Playbook. All of this is achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality. v. Lab objectives The material covered for this hands-on training is intended to prepare IBM sellers and business partners with the skills necessary to create Ansible automation tasks using the generative AI capabilities of WCA. The curriculum will leverage WCA's generative AI code recommendations for automating cloud-based and infrastructure-based automation tasks. In-depth explanations accompanying Ansible Playbook templates will also explain: How WCA uses natural language prompts , as well as Ansible Playbook contents, to generate contextually-aware Task code recommendations Post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How WCA provides content source matching attribution and \"explainability\" for all AI-generated content Leveraging WCA's model tuning capabilities to tailor content and code recommendations to an organization's standards, best practices, and programming styles vi. Next steps The module ahead will outline the evaluation criteria for IBM sellers and business partners. Afterwards, you will setup your local environment with the necessary pre-requisites for getting started with the hands-on material.","title":"Introduction"},{"location":"#_1","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) introduces IBM watsonx Code Assistant's generative AI capabilities and lays the groundwork for the hands-on training that will follow. [6 min]","title":""},{"location":"#i-automation-is-indispensable-to-modern-it-strategy","text":"Despite the innovations and advancements made in the domain of automation, IBM sellers and partners know first-hand from discussions with clients that many businesses are still struggling to keep up with their IT operations. The rapid pace of technological innovation\u2014 in particular, areas such as AI and machine learning \u2014are obviously challenging for any organization to strategize and plan around. But smaller, more practical challenges also stand in the way of these businesses. The fact remains that IT operations, and wrangling those operations in an efficient and streamlined manner, remains a difficult problem to solve. Three primary pain points that IBM consistently hears from the marketplace include: an ever-increasing skills gap in IT management; that Day 2 operations continue to be labor-intensive, mostly manual endeavors; and that the complexity of the systems needing to be managed are out-pacing many organization\u2019s ability to adapt. All of these pain points are potential automation challenges to be solved. Each of them impedes a company's ability to move quickly and adapt for the future. And as such, for many IBM clients, solving these automation challenges have become an indispensable element in their strategy to modernize IT. UNPRECEDENTED RATE OF GENERATIVE AI ADOPTION Even though generative AI is relatively new, the widespread popularity of ChatGPT has created significant interest in the notion of large language models (LLMs) and foundation models (FMs) \u2014 and what they can do for business. It took quite some time for enterprises to start moving toward traditional AI. In contrast, generative AI has experienced massive early adoption: 80% of enterprises are already working with, or planning to leverage FMs, and plan to adopt generative AI in their use cases and workflow. Moreover, the following data points to an ever-growing adoption trend for generative AI: Scale Zeitgeist 2023 AI Readiness Report notes that with the companies they reviewed, 21% have generative AI models in production; 29% are experimenting with generative AI and another 31% are planning to work with generative AI models; a total of 81% are either working with or planning to work with generative AI models Goldman Sachs has estimated that generative AI will have a very deep economic impact \u2013 raising global Gross Domestic Product (GDP) by 7% within 10 years, reflecting the technology\u2019s huge potential. Boston Consulting Group (BCG) noted that generative AI is expected to represent 30% of the overall market by 2025","title":"i. Automation is indispensable to modern IT strategy"},{"location":"#ii-generative-ai-assisted-code-lifecycle-management-achieves-what-llms-alone-cannot","text":"Following the debut of OpenAI's ChatGPT, the marketplace has been awash with competing large language model (LLM) and generative AI-based assistants. It's one thing to train and deploy an LLM; it's another thing entirely to make it applicable and tangibly beneficial for business. What separates IBM watsonx Code Assistant (WCA) offerings from competing vendors in the marketplace? The design and implementation of WCA is purposely built to assist, using generative AI, software and code lifecycle management. In short, generative AI-assisted code lifecycle management helps to achieve what large language models cannot achieve on their own. It is what distinguished WCA from other code assistants in the marketplace today. Code lifecycle management begins with understanding client code, through training across a myriad of programming languages and specializations in paradigms such as Ansible Automation Platform, and applies that understanding across a client\u2019s application and runtime environments. Users are able to plan next steps based on generative AI analysis of their existing application code. Operations teams can rapidly transform their codebases with optimized design and architecture that is recommended according to IBM Granite's best-practice models. Administrators can validate the outcomes with automatically generated unit tests. Afterwards, they can deploy those services and applications using automated processes like Ansible's automation engine. Over the course of that application or code's lifecycle, generative AI can maintain healthy operations with runtime insights.","title":"ii. Generative AI-assisted code lifecycle management achieves what LLMs alone cannot"},{"location":"#iii-introducing-the-ibm-watsonx-code-assistant-product-family","text":"IBM watsonx Code Assistant is the flagship offering in a suite of generative AI code assistant products, which also include offerings for Ansible Automation Platform (IBM watsonx Code Assistant for Red Hat Ansible Lightspeed) and IBM Systems modernization (IBM watsonx Code Assistant for Z). These solutions accelerate software development tasks with AI-powered capabilities including context-aware code generation, explanation, documentation, translation, and unit test generation. It does so while maintaining the principles of trust, security, and compliance with regards to IBM client's data and intellectual property. Developers and IT Operators can utilize WCA to speed up application modernization efforts and generate Ansible-based automation jobs to rapidly scale out (or scale up) IT environments. IBM watsonx Code Assistant products are powered by IBM Granite foundation models that include state-of-the-art large language models designed for code. For offerings such as WCA for Ansible Lightspeed and WCA for Z, bespoke code models\u2014 tailored to working with Ansible Automation Platform and COBOL-to-Z use cases, respectively \u2014are invoked. Universally true for all of the watsonx Code Assistant offerings is that they are geared towards helping IT teams create high-quality code using AI-generated recommendations, based on natural language requests or existing source code. These AI models, and the recommendations they generate, are seamlessly integrated via extensions with the world's most popular developer integrated development environments (IDE), including Visual Studio Code and Eclipse. Granite is IBM\u2019s flagship brand of open and proprietary LLMs, spanning multiple modalities. Granite models exist for code, languages, time series, and GeoSpatial \u2014 with additional modalities expected in future. IBM Granite code models are a series of decoder-only models for code generative tasks, trained with code written in 116 different programming languages. The Granite code models family consists of models ranging in size from 3 to 34 billion parameters, in both a base model and instruction-following model variants. These models have a range of uses, from complex application modernization tasks to on-device memory-constrained use cases. The larger the block size for a particular language on this chart, the larger percentage of training corpus data of that language was used to train the Granite code model. Languages and formats such as Java, C, JSON, JavaScript, HTML, and PHP are subjects in which the model \u201cMajors\u201d and excels. Other languages such as Ruby, SQL, and Swift could be considered \u201cMinors\u201d where the generalized code model can work with the language, but has less training data to base those recommendations on. These percentages and training data volumes will continue to evolve as the Granite code models mature. WATSONX CODE ASSISTANT vs. WCA FOR ANSIBLE LIGHTSPEED? For those familiar with other IBM watsonx Code Assistant offerings\u2014 such as WCA for Red Hat Ansible Lightspeed and WCA for Z \u2014the generalized code model approach, as seen here, differs from the specialized code model approach of those two aforementioned offerings. The WCA for Ansible Lightspeed flavor of IBM Granite code models specializes (Majors) only in Ansible Playbooks and YAML Similarly, the IBM Granite code model used by WCA for Z specializes in transforming COBOL mainframe code into modernized Java code Ansible Playbooks (YAML) and mainframe (COBOL) code are both supported (Minor) languages for the generalized IBM Granite code models\u2014 and therefore are supported by IBM watsonx Code Assistant \u2014but if a client wishes to specialize in those particular languages and frameworks, they would be well advised to utilize the bespoke WCA for Ansible Lightspeed and WCA for Z offerings, respectively, to do so.","title":"iii. Introducing the IBM watsonx Code Assistant product family"},{"location":"#iv-solution-architecture-of-ibm-watsonx-code-assistant-for-red-hat-ansible-lightspeed","text":"IBM watsonx Code Assistant for Red Hat Ansible Lightspeed meets developers where they are: with a rich plugin via VS Code extensions, where developers input their prompts directly in the code editor. Prompts are sent to the Ansible Lightspeed service, and the service sends a suggestion back (a completion ) that\u2019s powered by IBM Granite LLMs for code. It is important to note that all data in transit is encrypted and ephemeral so users can be confident and have trust in the security of the service during this exchange. In terms of data security, client Ansible playbooks and customized models that they may potentially have are stored in client-owned Cloud Object Storage and are not shared with IBM, Red Hat, or any other clients. In order to utilize IBM watsonx Code Assistant for Red Hat Ansible Lightspeed, a client must have an existing license for Red Hat Ansible Automation Platform (the \u201dred tile\u201d component in the center of the diagram), as well as a license for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed (the \u201cblue tile\u201d on the right of the diagram). Generative AI has recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. For example, if trained on a large dataset of Ansible Playbooks, generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. WHAT ARE PLAYBOOKS? Ansible Playbooks instruct Ansible\u2019s automation engine on how to execute tasks in a step-by-step manner. Playbooks defines roles, tasks, handlers, and other configurations; in turn, these attributes allow developers and users to codify complex orchestration scenarios. Conceptually, think of a Playbook as a recipe book for system administration: each recipe (or Playbook) spells out the steps required to achieve a particular system state or to complete a given operation. One of the standout features of Ansible Playbooks is that they are idempotent : executing Playbooks multiple times on the same system won't create additional \"side effects\" (unintended operations or creation of unwanted artifacts) after the first successful run. This ensures consistency and reliability across deployments of the Red Hat Ansible Automation Platform ( AAP ). As you will see throughout the hands-on training material, generative AI models provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language ( \"I want a Playbook to install and start an Apache web server\" ) and the model will generate the appropriate Ansible Tasks for a Playbook. All of this is achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality.","title":"iv. Solution architecture of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed"},{"location":"#v-lab-objectives","text":"The material covered for this hands-on training is intended to prepare IBM sellers and business partners with the skills necessary to create Ansible automation tasks using the generative AI capabilities of WCA. The curriculum will leverage WCA's generative AI code recommendations for automating cloud-based and infrastructure-based automation tasks. In-depth explanations accompanying Ansible Playbook templates will also explain: How WCA uses natural language prompts , as well as Ansible Playbook contents, to generate contextually-aware Task code recommendations Post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How WCA provides content source matching attribution and \"explainability\" for all AI-generated content Leveraging WCA's model tuning capabilities to tailor content and code recommendations to an organization's standards, best practices, and programming styles","title":"v. Lab objectives"},{"location":"#vi-next-steps","text":"The module ahead will outline the evaluation criteria for IBM sellers and business partners. Afterwards, you will setup your local environment with the necessary pre-requisites for getting started with the hands-on material.","title":"vi. Next steps"},{"location":"generating/","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed An Ansible Task is a statement in Ansible's automation script (the YAML-based Playbooks you will be working with) that declares a single action to be executed. This might be installing a package, copying a file, or shutting down a service on a remote machine. Each Task represents an idempotent operation (an action that can be repeated multiple times and deliver the same result every time) that aligns the remote managed node to the specified state. Idempotent operations also ensure consistency across multiple executions, guaranteeing the same steps are taken on each execution of the task. After you have learned the fundamentals of generating Ansible Task code blocks using IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ), you'll be ready to shape and tailor the AI-generated code recommendations using WCA's model tuning capabilities. ii. Single task Ansible operations The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of an action that is to be executed, which always start with - name: and are followed by some description of the task to be performed. Ansible Tasks are often preceded with the prefix # , indicating developer comments or documentation. After the natural language description of the automation Task has been set by the user, WCA handles the rest. WCA is also capable of generating multiple Ansible Tasks from more complex natural language descriptions\u2014 what is referred to as multi-task code generation \u2014which you will experiment with later in this module. However, to get started, let's begin with the basics of generating code for single task use cases. Begin by opening the install_cockpit_single-task.yml Playbook from the list of assets in the Explorer browser. Click the Explorer tab from the left-hand interface [A] Drill down into the Install and configure Cockpit using Ansible subdirectory [B] Double-click the install_cockpit_single-task.yml Playbook A replica of the Playbook code is also included below in the documentation The red highlighting within the editor reminds users that the tasks: section contains no valid -name: task definitions. This is part of WCA's code validation process which runs automatically and alerts users to syntax errors in their code. You can safely ignore these warnings for now, as you will be un-commenting and generating valid -name: task definitions in the following steps. ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The install_cockpit_single-task.yml Playbook code above warrants some explanation before we move on with making AI-generated modifications to it: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 3-4 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which you will explore in much finer details later on in this module. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by WCA for context when generating code recommendations. You will experiment with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. Cockpit is an interactive server administration interface that provides a graphical overview of statistics and configurations for a system or systems within a network. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15 , which in sequence from left to right are as follows: begins with Tab (or Space whitespaces) for indentation a # character to \"comment out\" the line's contents a whitespace Space character - name: which signifies the start of a Task definition and finally the natural language description of the Task INDENTATION LEVELS AND WHITESPACE Similar to Python, Ansible and YAML-based Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the Tab in this example) denote different hierarchies and code nesting levels within the YAML structure. You may use Space instead of Tab if you prefer, but be sure to use indentations consistently : choose to use either Tab or Space for indenting lines of code, and do not interchange between the two. To generate code for TASK 1 , first uncomment the line of code (remove the # character from the start of a line). Highlight the line(s) of code you wish to uncomment and then press Cmd + ? for macOS or Ctrl + ? for Windows You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code Tip: commented out lines of code in VS Code will appear as green text Afterwards, Line 15 should look like the following \u2014 beginning with a single Tab - name : Install cockpit package Now you are ready to begin generating code. Place your cursor on Line 15 and hit Enter Wait for WCA to engage and generate the suggested (in grey, italicized text ) code block for executing the task This temporary code suggestion is entirely generated by AI As a user, you have the option to either: Accept the code recommendation as-given by pressing Tab Modify the recommended code by highlighting and replacing the italicized text FAILED TO CONNECT TO THE SERVER / \"YOU DON'T HAVE ACCESS TO IBM WATSONX...\" This warning will occur when the Ansible plugin for VS Code needs to be re-authenticated with WCA. It can occur after an extended period of inactivity or a system restart. For example, if your lab environment is running inside a VM, pausing or restarting the VM may produce this error. To re-authenticate: Sign out from the VS Code application by clicking the User icon [A] in the bottom-left corner of the interface, hover over your username, and then click Sign Out [B] If you are running this environment inside a virtual machine (VM) , closing and restarting the VM will not resolve the issue \u2014 you must sign out from the VS Code application, not the VM Once logged out, follow from Step 7 of the Setup & Troubleshooting to re-authenticate with WCA CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible \"ANSIBLE-LINT IS NOT AVAILABLE.\" ansible-lint checks Playbooks for practices and behavior that could potentially be improved and can fix some of the most common ones for you. It will constantly check your Ansible syntax as you type and provide recommendations for how to improve it. You can safely ignore this error if it occurs during the lab exercises If you wish to install ansible-lint on your local machine, execute the following instruction within a Terminal console: python3 -m pip install --upgrade --user ansible-lint Hit Tab to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, WCA was asked to include the cockpit Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked a Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by WCA. Additional examples of infusing best-practices into AI-generated code recommendations can be found in TASK 2 ( Line 21 of the unmodified template or Line 25 after Step 5 ): Uncomment - name: Copy cockpit.conf.j2 to /etc/cockpit Hit Enter to generate the task code recommendation and accept the AI-suggested code (without modifications) by pressing Tab Compare your results with the SOLUTION tab below TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. Setting a file permission to 0644 specifies read and write permissions for User and Group levels within the Linux OS, and provides only read permissions to all others. iii. Multi-task Ansible operations Up to this point, we've kept a narrow aperture on AI-generated recommendations for single tasks \u2014 examining and experimenting with generating Ansible code task by task, one at a time. However, a powerful WCA feature is the ability to combine multiple task descriptions into a single natural language prompt; in turn, WCA is able to parse that instruction, decompose the instruction into discrete Ansible Task parts, and return a complete code recommendation for achieving the author's intended goal. Syntactically, multiple tasks are combined into a single natural language expression through the use of ampersand ( & ) characters. Simply write out all the automation task descriptions on a single line, separating each description with a & character. The line must also begin with a # character for reasons that will be explained shortly. To illustrate, let's look at a multi-task Ansible Playbook: install_cockpit_multi-task.yml The contents of this Playbook should look familiar to you already: it is essentially the same Playbook examined in Steps 1-6 ( install_cockpit_single-task.yml ), re-written in an equivalent multi-task expression Each of the Task descriptions from the previous Playbook have been consolidated into a single description on Line 12 , separated by & characters ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_multi-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : # Install cockpit package & Copy cockpit.conf.j2 to /etc/cockpit & Start and enable service & Wait 15 seconds port 9090 There are two crucial distinctions between single task and multi-task code generation: formatting and execution. Formatting : Notice that Line 12 does not begin with -name: , as was the case with single task descriptions Execution : In order to generate AI code recommendations for multi-task descriptions, Line 12 must stay commented out (the # must remain at the start of the line) What is the rationale behind this? When WCA's generative AI capabilities parse Line 12 , its output will include multiple -name: tasks, each containing potentially multiple lines of instructions, based on how many & -delineated task descriptions are included on the line. Therefore, the way in which the code generation step is executed on Line 12 is a consequence of the formatting decision. Execution of a code generation step on a commented-out ( # ) line containing & delineators is recognized by WCA as a unique case that will be acted upon as a multi-task statement. Place your cursor at the end of Line 12 , and without removing the # character, press Enter to execute the code generation step. Be aware that generating code for multi-task descriptions will take longer compared to a single task. Compare the MULTI-TASK solution tab with the SINGLE TASK solution (copied over from Step 6 ). How did the multi-task code generation fare compared to the single task approach? MULTI-TASK SINGLE TASK 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit.socket - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit state : started enabled : true - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 Comparing the two results, the only notable difference between the two approaches are Lines 27-29 from the SINGLE TASK generative AI approach. Both the SINGLE TASK and MULTI-TASK suggestions for that particular task satisfy the request made by the user. However, whether the single task or multi-task approach resulted in a better code suggestion is up to the judgement of the programmer. Nearly 90% of the remaining code was identical between the two approaches and was achieved in far fewer lines of code (and less typing) using the multi-task approach. The variability of generative AI suggestions is a fascinating topic and one that we will dive more deeply into with the module ahead. Before moving on to other product features, experiment by creating a new Ansible Playbook in your workspace using the code template below. Suggestions will be given on how to perform the same automation task using single and multi-task generation approaches. Save the YAML file as create_ec2_single_multi.yml (if you forget to save the file, WCA will not generate recommendations) Copy the following code block to your clipboard using the + icon in the top-right corner of the panel and paste into the newly created YAML file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ~/Documents/ansible-wca-demo-kit/create_ec2_single_multi.yml 1 2 3 4 --- - name : Provision an EC2 instance hosts : all tasks : First, configure the Playbook for single task generation by adding the following code snippet into Line 5 (remembering to properly indent with Tab or Space characters): - name : create vpc named demo Your workspace Playbook should look identical to the TEMPLATE tab below. Place your cursor at the end of the newly-created Line 5 and hit Enter to execute single task code generation. Compare your results to the SOLUTION tab. Record your results to a notepad so that you can compare the results later. TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc Now it's time to re-write the Playbook for multi-task code generation. The beauty of natural language statements is that your approach can be as terse or verbose as you want. The more verbose and descriptive, the more prescriptive you can be in terms of influencing the AI-generated code recommendations from WCA. The topic of \"prompt tuning\" will be explored in much greater detail in the Task Description Tuning and Model Customization module. But for now: Replace all of the code inside create_ec2_single_multi.yml with the TEMPLATE code block (below) Place your cursor at the end of Line 5 (remember not to remove the # character) and hit Enter , then accept the recommendation with Tab Compare your results to the SOLUTION tab and to the result from Step 13 TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet - name : Create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc - name : Create security group for demo vpc and allow ssh and http amazon.aws.ec2_security_group : name : demo description : demo security group vpc_id : \"{ vpc.vpc.id }\" rules : - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 register : sg - name : Create internet gateway named demogateway for demo vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demogateway register : igw - name : Create subnet named demosubnet in demo vpc amazon.aws.ec2_vpc_subnet : cidr : 10.0.0.80/24 vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet register : subnet - name : Create route table for subnet demosubnet and gateway demogateway amazon.aws.ec2_vpc_route_table : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet subnets : - \"{ subnet.subnet.id }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ igw.gateway_id }\" register : route_table - name : Create t2.small ec2 instance in subnet demosubnet amazon.aws.ec2_instance : key_name : \"{ _key_name_ }\" instance_type : t2.small image : \"{ _image_ }\" wait : true vpc_subnet_id : \"{ subnet.subnet.id }\" security_group : demo register : ec2 TIMEOUT WARNING It may take several moments for WCA to process and return code recommendations for a multi-task description as complex as this one. If you receive a time-out warning, try executing the code generation step by pressing Enter a second time. iv. Next steps In the next section, you will examine in detail WCA's post-processing and content source attribution capabilities.","title":"Generating"},{"location":"generating/#_1","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":""},{"location":"generating/#i-generating-code-with-ibm-watsonx-code-assistant-for-red-hat-ansible-lightspeed","text":"An Ansible Task is a statement in Ansible's automation script (the YAML-based Playbooks you will be working with) that declares a single action to be executed. This might be installing a package, copying a file, or shutting down a service on a remote machine. Each Task represents an idempotent operation (an action that can be repeated multiple times and deliver the same result every time) that aligns the remote managed node to the specified state. Idempotent operations also ensure consistency across multiple executions, guaranteeing the same steps are taken on each execution of the task. After you have learned the fundamentals of generating Ansible Task code blocks using IBM watsonx Code Assistant for Red Hat Ansible Lightspeed ( WCA ), you'll be ready to shape and tailor the AI-generated code recommendations using WCA's model tuning capabilities.","title":"i. Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed"},{"location":"generating/#ii-single-task-ansible-operations","text":"The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of an action that is to be executed, which always start with - name: and are followed by some description of the task to be performed. Ansible Tasks are often preceded with the prefix # , indicating developer comments or documentation. After the natural language description of the automation Task has been set by the user, WCA handles the rest. WCA is also capable of generating multiple Ansible Tasks from more complex natural language descriptions\u2014 what is referred to as multi-task code generation \u2014which you will experiment with later in this module. However, to get started, let's begin with the basics of generating code for single task use cases. Begin by opening the install_cockpit_single-task.yml Playbook from the list of assets in the Explorer browser. Click the Explorer tab from the left-hand interface [A] Drill down into the Install and configure Cockpit using Ansible subdirectory [B] Double-click the install_cockpit_single-task.yml Playbook A replica of the Playbook code is also included below in the documentation The red highlighting within the editor reminds users that the tasks: section contains no valid -name: task definitions. This is part of WCA's code validation process which runs automatically and alerts users to syntax errors in their code. You can safely ignore these warnings for now, as you will be un-commenting and generating valid -name: task definitions in the following steps. ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_single-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The install_cockpit_single-task.yml Playbook code above warrants some explanation before we move on with making AI-generated modifications to it: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 3-4 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which you will explore in much finer details later on in this module. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by WCA for context when generating code recommendations. You will experiment with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. Cockpit is an interactive server administration interface that provides a graphical overview of statistics and configurations for a system or systems within a network. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15 , which in sequence from left to right are as follows: begins with Tab (or Space whitespaces) for indentation a # character to \"comment out\" the line's contents a whitespace Space character - name: which signifies the start of a Task definition and finally the natural language description of the Task INDENTATION LEVELS AND WHITESPACE Similar to Python, Ansible and YAML-based Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the Tab in this example) denote different hierarchies and code nesting levels within the YAML structure. You may use Space instead of Tab if you prefer, but be sure to use indentations consistently : choose to use either Tab or Space for indenting lines of code, and do not interchange between the two. To generate code for TASK 1 , first uncomment the line of code (remove the # character from the start of a line). Highlight the line(s) of code you wish to uncomment and then press Cmd + ? for macOS or Ctrl + ? for Windows You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code Tip: commented out lines of code in VS Code will appear as green text Afterwards, Line 15 should look like the following \u2014 beginning with a single Tab - name : Install cockpit package Now you are ready to begin generating code. Place your cursor on Line 15 and hit Enter Wait for WCA to engage and generate the suggested (in grey, italicized text ) code block for executing the task This temporary code suggestion is entirely generated by AI As a user, you have the option to either: Accept the code recommendation as-given by pressing Tab Modify the recommended code by highlighting and replacing the italicized text FAILED TO CONNECT TO THE SERVER / \"YOU DON'T HAVE ACCESS TO IBM WATSONX...\" This warning will occur when the Ansible plugin for VS Code needs to be re-authenticated with WCA. It can occur after an extended period of inactivity or a system restart. For example, if your lab environment is running inside a VM, pausing or restarting the VM may produce this error. To re-authenticate: Sign out from the VS Code application by clicking the User icon [A] in the bottom-left corner of the interface, hover over your username, and then click Sign Out [B] If you are running this environment inside a virtual machine (VM) , closing and restarting the VM will not resolve the issue \u2014 you must sign out from the VS Code application, not the VM Once logged out, follow from Step 7 of the Setup & Troubleshooting to re-authenticate with WCA CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible \"ANSIBLE-LINT IS NOT AVAILABLE.\" ansible-lint checks Playbooks for practices and behavior that could potentially be improved and can fix some of the most common ones for you. It will constantly check your Ansible syntax as you type and provide recommendations for how to improve it. You can safely ignore this error if it occurs during the lab exercises If you wish to install ansible-lint on your local machine, execute the following instruction within a Terminal console: python3 -m pip install --upgrade --user ansible-lint Hit Tab to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, WCA was asked to include the cockpit Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked a Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by WCA. Additional examples of infusing best-practices into AI-generated code recommendations can be found in TASK 2 ( Line 21 of the unmodified template or Line 25 after Step 5 ): Uncomment - name: Copy cockpit.conf.j2 to /etc/cockpit Hit Enter to generate the task code recommendation and accept the AI-suggested code (without modifications) by pressing Tab Compare your results with the SOLUTION tab below TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. Setting a file permission to 0644 specifies read and write permissions for User and Group levels within the Linux OS, and provides only read permissions to all others.","title":"ii. Single task Ansible operations"},{"location":"generating/#iii-multi-task-ansible-operations","text":"Up to this point, we've kept a narrow aperture on AI-generated recommendations for single tasks \u2014 examining and experimenting with generating Ansible code task by task, one at a time. However, a powerful WCA feature is the ability to combine multiple task descriptions into a single natural language prompt; in turn, WCA is able to parse that instruction, decompose the instruction into discrete Ansible Task parts, and return a complete code recommendation for achieving the author's intended goal. Syntactically, multiple tasks are combined into a single natural language expression through the use of ampersand ( & ) characters. Simply write out all the automation task descriptions on a single line, separating each description with a & character. The line must also begin with a # character for reasons that will be explained shortly. To illustrate, let's look at a multi-task Ansible Playbook: install_cockpit_multi-task.yml The contents of this Playbook should look familiar to you already: it is essentially the same Playbook examined in Steps 1-6 ( install_cockpit_single-task.yml ), re-written in an equivalent multi-task expression Each of the Task descriptions from the previous Playbook have been consolidated into a single description on Line 12 , separated by & characters ~/Documents/ansible-wca-demo-kit/install and configure Cockpit using Ansible/install_cockpit_multi-task.yml 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : # Install cockpit package & Copy cockpit.conf.j2 to /etc/cockpit & Start and enable service & Wait 15 seconds port 9090 There are two crucial distinctions between single task and multi-task code generation: formatting and execution. Formatting : Notice that Line 12 does not begin with -name: , as was the case with single task descriptions Execution : In order to generate AI code recommendations for multi-task descriptions, Line 12 must stay commented out (the # must remain at the start of the line) What is the rationale behind this? When WCA's generative AI capabilities parse Line 12 , its output will include multiple -name: tasks, each containing potentially multiple lines of instructions, based on how many & -delineated task descriptions are included on the line. Therefore, the way in which the code generation step is executed on Line 12 is a consequence of the formatting decision. Execution of a code generation step on a commented-out ( # ) line containing & delineators is recognized by WCA as a unique case that will be acted upon as a multi-task statement. Place your cursor at the end of Line 12 , and without removing the # character, press Enter to execute the code generation step. Be aware that generating code for multi-task descriptions will take longer compared to a single task. Compare the MULTI-TASK solution tab with the SINGLE TASK solution (copied over from Step 6 ). How did the multi-task code generation fare compared to the single task approach? MULTI-TASK SINGLE TASK 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit.socket - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 --- - name : Install and configure Cockpit hosts : rhel become : true module_defaults : ansible.builtin.service : enabled : true state : started tasks : - name : Install cockpit package ansible.builtin.package : name : cockpit state : present - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' - name : Start and enable service ansible.builtin.service : name : cockpit state : started enabled : true - name : Wait 15 seconds port 9090 ansible.builtin.wait_for : port : 9090 delay : 15 Comparing the two results, the only notable difference between the two approaches are Lines 27-29 from the SINGLE TASK generative AI approach. Both the SINGLE TASK and MULTI-TASK suggestions for that particular task satisfy the request made by the user. However, whether the single task or multi-task approach resulted in a better code suggestion is up to the judgement of the programmer. Nearly 90% of the remaining code was identical between the two approaches and was achieved in far fewer lines of code (and less typing) using the multi-task approach. The variability of generative AI suggestions is a fascinating topic and one that we will dive more deeply into with the module ahead. Before moving on to other product features, experiment by creating a new Ansible Playbook in your workspace using the code template below. Suggestions will be given on how to perform the same automation task using single and multi-task generation approaches. Save the YAML file as create_ec2_single_multi.yml (if you forget to save the file, WCA will not generate recommendations) Copy the following code block to your clipboard using the + icon in the top-right corner of the panel and paste into the newly created YAML file HOW TO CREATE NEW YAML PLAYBOOKS Note: You need to copy and paste the contents of the Playbook into a New File... within the same Lightspeed project directory that was used for the previous lab modules in order for the VS Code extension to engage. To create a new YAML Playbook within a VS Code environment: a. Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. b. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. c. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Save it to one of the directories in the ansible-wca-demo-kit folder. d. Paste the clipboard contents into the YAML file and follow along with the suggestions below. COPY AND PASTE CODE WITHIN THE VM Information \"copied\" to your local machine's clipboard cannot be \"pasted\" directly into the virtual machine (VM) environment or VS Code. If you wish to copy and paste instructions directly from the lab documentation, it is recommended that you open the GitHub instructions inside the VM's web browser (Firefox). This will allow you to copy instructions to the VM's clipboard and paste instructions inside the VS Code editor. ANSIBLE LIGHTSPEED IS MISSING OR CODE RECOMMENDATIONS ARE NOT GENERATING Ansible Lightspeed and WCA will only generate code recommendations for Ansible Playbooks and YAML files. VS Code will typically auto-detect the programming language of the document you're working with, but on occassion you may need to manually specify the language. Even if working with a YAML file, you'll still need to specify the language mode as Ansible for the Lightspeed plugin to engage. To set the language mode correctly: In the bottom-right corner of the VS Code interface, hover over the Select Language Mode toggle [A] A console will appear at the top of VS Code with a drop-down list of options [B] Click Ansible from the suggested languages, or enter the text yourself and hit Enter Confirm that the Select Language Mode toggle in the bottom-right corner displays Ansible ~/Documents/ansible-wca-demo-kit/create_ec2_single_multi.yml 1 2 3 4 --- - name : Provision an EC2 instance hosts : all tasks : First, configure the Playbook for single task generation by adding the following code snippet into Line 5 (remembering to properly indent with Tab or Space characters): - name : create vpc named demo Your workspace Playbook should look identical to the TEMPLATE tab below. Place your cursor at the end of the newly-created Line 5 and hit Enter to execute single task code generation. Compare your results to the SOLUTION tab. Record your results to a notepad so that you can compare the results later. TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo 1 2 3 4 5 6 7 8 9 10 11 12 --- - name : Provision an EC2 instance hosts : all tasks : - name : create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc Now it's time to re-write the Playbook for multi-task code generation. The beauty of natural language statements is that your approach can be as terse or verbose as you want. The more verbose and descriptive, the more prescriptive you can be in terms of influencing the AI-generated code recommendations from WCA. The topic of \"prompt tuning\" will be explored in much greater detail in the Task Description Tuning and Model Customization module. But for now: Replace all of the code inside create_ec2_single_multi.yml with the TEMPLATE code block (below) Place your cursor at the end of Line 5 (remember not to remove the # character) and hit Enter , then accept the recommendation with Tab Compare your results to the SOLUTION tab and to the result from Step 13 TEMPLATE SOLUTION 1 2 3 4 5 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 --- - name : Provision an EC2 instance hosts : all tasks : # create vpc named demo & create security group for demo vpc and allow ssh and http & create internet gateway named demogateway for demo vpc & create subnet named demosubnet in demo vpc & create route table for subnet demosubnet and gateway demogateway & create t2.small ec2 instance in subnet demosubnet - name : Create vpc named demo amazon.aws.ec2_vpc_net : name : demo cidr_block : 10.0.0.80/16 tags : Name : demo tenancy : default register : vpc - name : Create security group for demo vpc and allow ssh and http amazon.aws.ec2_security_group : name : demo description : demo security group vpc_id : \"{ vpc.vpc.id }\" rules : - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 register : sg - name : Create internet gateway named demogateway for demo vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demogateway register : igw - name : Create subnet named demosubnet in demo vpc amazon.aws.ec2_vpc_subnet : cidr : 10.0.0.80/24 vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet register : subnet - name : Create route table for subnet demosubnet and gateway demogateway amazon.aws.ec2_vpc_route_table : vpc_id : \"{ vpc.vpc.id }\" tags : Name : demosubnet subnets : - \"{ subnet.subnet.id }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ igw.gateway_id }\" register : route_table - name : Create t2.small ec2 instance in subnet demosubnet amazon.aws.ec2_instance : key_name : \"{ _key_name_ }\" instance_type : t2.small image : \"{ _image_ }\" wait : true vpc_subnet_id : \"{ subnet.subnet.id }\" security_group : demo register : ec2 TIMEOUT WARNING It may take several moments for WCA to process and return code recommendations for a multi-task description as complex as this one. If you receive a time-out warning, try executing the code generation step by pressing Enter a second time.","title":"iii. Multi-task Ansible operations"},{"location":"generating/#iv-next-steps","text":"In the next section, you will examine in detail WCA's post-processing and content source attribution capabilities.","title":"iv. Next steps"},{"location":"on-premises/1/","text":"Objectives and Requirements On-Premises Installation and Deployment i. Introduction and hands-on objectives The On-Premises Installation and Deployment module provides comprehensive instructions for how to prepare, configure, and deploy a simulated on-premises cluster for IBM watsonx Code Assistant (WCA) on environments hosted by IBM Technology Zone (ITZ). By completing this module, participants will have learned and applied the skills necessary for deploying WCA on a client's on-premises infrastructure. The complete stack of technologies and services that you will deploy include: Red Hat OpenShift Container Platform v4.18 : a unified application development platform that lets clients build, modernize, and deploy applications at scale on their choice of hybrid cloud infrastructure. IBM Cloud Pak for Data v5.1.x : a set of services comprising a data fabric solution for data governance, data engineering, data analysis, and AI lifecycle tasks. IBM Software Hub v5.1 : a cloud-native solution that clients use to install, manage, and monitor IBM solutions on Red Hat OpenShift Container Platform. IBM watsonx Code Assistant v5.1 : a generative AI coding companion that provides contextually aware assistance for programming languages. Special acknowledgement and thanks to IBM colleagues Coralie Jonvel, Nelson Nunes, and Noe Samaille for adaptation of their deployment instructions for watsonx.ai on Red Hat OpenShift. INSERT ARCHITECTURE GRAPHIC AND DESCRIPTION HERE NEEDS DISCLAIMER THAT INSTALLATION WILL NOT RESULT IN A FULLY FUNCTIONAL CLUSTER (GPUs) ii. Infrastructure and resource requirements Requirements specific to the hands-on environment are outlined in the section below. Comprehensive details about the hardware requirements for x86_64 cluster services are available from IBM Software Hub documentation. Although the hands-on environment that will be provisioned in the next module utilizes a templated, pre-defined ITZ infrastructure configuration, it will be useful for those enrolled to understand the resources required to reproduce a similar cluster in real-world client scenarios. This includes details about the CPU, memory, GPU, and other hardware components required to support the necessary cluster services. IBM Software Hub platform Additional details available from IBM Documentation Node Role Number of Services Minimum Available vCPU Minimum Memory Minimum Storage Control plane 3 (for high availability) 4 vCPU per node (This configuration supports up to 24 worker nodes.) 16 GB RAM per node. This configuration supports up to 24 worker nodes. No additional storage is needed for IBM Software Hub. Infra 3 (recommended) 4 vCPU per node. This configuration supports up to 27 worker nodes. 24 GB RAM per node (This configuration supports up to 27 worker nodes.) See the Red Hat OpenShift Container Platform documentation for sizing guidance. Worker (compute) 3 or more worker (compute) nodes 16 vCPU per node Minimum : 64 GB RAM per node Recommended : 128 GB RAM per node 300 GB of storage space per node for storing container images locally. If you plan to install watsonx.ai, increase the storage to 500 GB per node. Load balancer 2 load balancer nodes 2 vCPU per node 4 GB RAM per node. Add another 4 GB of RAM for access restrictions and security control. Add 100 GB of root storage for access restrictions and security control. IBM Cloud Pak Foundational Services Additional details available from IBM Documentation vCPU Memory Storage Notes 4 vCPU 5 GB RAM Reference the v4.10 hardware requirements and recommendations . Required. IBM Cloud Pak Foundational Services are installed once for each instance of IBM Software Hub on the cluster. Red Hat OpenShift Container Platform (single node) Additional details available from IBM Documentation VM Role Minimum Available vCPU Minimum Memory Minimum Storage Bastion node 4 vCPU 8 GB RAM Allocate a minimum of 500 GB of disk space. The disk can be: in the same disk as the general bastion node storage; in a separate disk on the bastion node; or on external storage. Worker (compute) 16 vCPU 64 GB RAM Allocate a minimum of 300 GB of disk space on the node for image storage. IBM watsonx Code Assistant Additional details available from IBM Documentation vCPU Memory Storage Notes Operator pods: 0.1 vCPU Operator pods: 0.256 GB RAM Persistent storage: 120 GB Minimum resources for an installation with a single replica per service Catalog pods: 0.01 vCPU Catalog pods: 0.05 GB RAM Ephemeral storage: 0.4 GB The service requires at least two GPUs Operand: 7 vCPU Operand: 25 GB RAM Image storage: Up to 107 GB with all models GPU support is limited to: NVIDIA H100 GPUs with 80 GB RAM iii. Prerequisites checklist Register for an IBM Technology Zone account Participants require access to ITZ in order to reserve an environment and complete the hands-on work. If you do not yet have an account with the ITZ, you will need to register for one . Obtain an IBM Entitlement API key Participants require an entitlement API key to proceed with the on-premises installation. In order to retrieve the key: Use your IBMid and password to log in to the Container Software Library . Click the Entitlement keys tab from the navigation menu. Select Copy to capture the entitlement key to the clipboard. Paste and save the entitlement key to a text file on your local machine. iv. Next steps In the following module, you will provision an OpenShift Container Platform cluster via IBM Technology Zone, which will serve as the basis for the on-premises environment.","title":"1. Objectives and requirements"},{"location":"on-premises/1/#objectives-and-requirementson-premises-installation-and-deployment","text":"","title":"Objectives and RequirementsOn-Premises Installation and Deployment"},{"location":"on-premises/1/#i-introduction-and-hands-on-objectives","text":"The On-Premises Installation and Deployment module provides comprehensive instructions for how to prepare, configure, and deploy a simulated on-premises cluster for IBM watsonx Code Assistant (WCA) on environments hosted by IBM Technology Zone (ITZ). By completing this module, participants will have learned and applied the skills necessary for deploying WCA on a client's on-premises infrastructure. The complete stack of technologies and services that you will deploy include: Red Hat OpenShift Container Platform v4.18 : a unified application development platform that lets clients build, modernize, and deploy applications at scale on their choice of hybrid cloud infrastructure. IBM Cloud Pak for Data v5.1.x : a set of services comprising a data fabric solution for data governance, data engineering, data analysis, and AI lifecycle tasks. IBM Software Hub v5.1 : a cloud-native solution that clients use to install, manage, and monitor IBM solutions on Red Hat OpenShift Container Platform. IBM watsonx Code Assistant v5.1 : a generative AI coding companion that provides contextually aware assistance for programming languages. Special acknowledgement and thanks to IBM colleagues Coralie Jonvel, Nelson Nunes, and Noe Samaille for adaptation of their deployment instructions for watsonx.ai on Red Hat OpenShift. INSERT ARCHITECTURE GRAPHIC AND DESCRIPTION HERE NEEDS DISCLAIMER THAT INSTALLATION WILL NOT RESULT IN A FULLY FUNCTIONAL CLUSTER (GPUs)","title":"i. Introduction and hands-on objectives"},{"location":"on-premises/1/#ii-infrastructure-and-resource-requirements","text":"Requirements specific to the hands-on environment are outlined in the section below. Comprehensive details about the hardware requirements for x86_64 cluster services are available from IBM Software Hub documentation. Although the hands-on environment that will be provisioned in the next module utilizes a templated, pre-defined ITZ infrastructure configuration, it will be useful for those enrolled to understand the resources required to reproduce a similar cluster in real-world client scenarios. This includes details about the CPU, memory, GPU, and other hardware components required to support the necessary cluster services. IBM Software Hub platform Additional details available from IBM Documentation Node Role Number of Services Minimum Available vCPU Minimum Memory Minimum Storage Control plane 3 (for high availability) 4 vCPU per node (This configuration supports up to 24 worker nodes.) 16 GB RAM per node. This configuration supports up to 24 worker nodes. No additional storage is needed for IBM Software Hub. Infra 3 (recommended) 4 vCPU per node. This configuration supports up to 27 worker nodes. 24 GB RAM per node (This configuration supports up to 27 worker nodes.) See the Red Hat OpenShift Container Platform documentation for sizing guidance. Worker (compute) 3 or more worker (compute) nodes 16 vCPU per node Minimum : 64 GB RAM per node Recommended : 128 GB RAM per node 300 GB of storage space per node for storing container images locally. If you plan to install watsonx.ai, increase the storage to 500 GB per node. Load balancer 2 load balancer nodes 2 vCPU per node 4 GB RAM per node. Add another 4 GB of RAM for access restrictions and security control. Add 100 GB of root storage for access restrictions and security control. IBM Cloud Pak Foundational Services Additional details available from IBM Documentation vCPU Memory Storage Notes 4 vCPU 5 GB RAM Reference the v4.10 hardware requirements and recommendations . Required. IBM Cloud Pak Foundational Services are installed once for each instance of IBM Software Hub on the cluster. Red Hat OpenShift Container Platform (single node) Additional details available from IBM Documentation VM Role Minimum Available vCPU Minimum Memory Minimum Storage Bastion node 4 vCPU 8 GB RAM Allocate a minimum of 500 GB of disk space. The disk can be: in the same disk as the general bastion node storage; in a separate disk on the bastion node; or on external storage. Worker (compute) 16 vCPU 64 GB RAM Allocate a minimum of 300 GB of disk space on the node for image storage. IBM watsonx Code Assistant Additional details available from IBM Documentation vCPU Memory Storage Notes Operator pods: 0.1 vCPU Operator pods: 0.256 GB RAM Persistent storage: 120 GB Minimum resources for an installation with a single replica per service Catalog pods: 0.01 vCPU Catalog pods: 0.05 GB RAM Ephemeral storage: 0.4 GB The service requires at least two GPUs Operand: 7 vCPU Operand: 25 GB RAM Image storage: Up to 107 GB with all models GPU support is limited to: NVIDIA H100 GPUs with 80 GB RAM","title":"ii. Infrastructure and resource requirements"},{"location":"on-premises/1/#iii-prerequisites-checklist","text":"Register for an IBM Technology Zone account Participants require access to ITZ in order to reserve an environment and complete the hands-on work. If you do not yet have an account with the ITZ, you will need to register for one . Obtain an IBM Entitlement API key Participants require an entitlement API key to proceed with the on-premises installation. In order to retrieve the key: Use your IBMid and password to log in to the Container Software Library . Click the Entitlement keys tab from the navigation menu. Select Copy to capture the entitlement key to the clipboard. Paste and save the entitlement key to a text file on your local machine.","title":"iii. Prerequisites checklist"},{"location":"on-premises/1/#iv-next-steps","text":"In the following module, you will provision an OpenShift Container Platform cluster via IBM Technology Zone, which will serve as the basis for the on-premises environment.","title":"iv. Next steps"},{"location":"on-premises/2/","text":"Reserve an Environment On-Premises Installation and Deployment If you require assistance or run into issues with the hands-on lab, help is available. Environment issues: The lab environment is managed by IBM Technology Zone. Opening a support case ticket is recommended for issues related to the hands-on environment (provisioning, running, and so on.) Documentation issues: If there is an error in the lab documentation, or if you require additional support in completing the material, open a thread on the #wca-ansible-techzone-support Slack channel. i. Configuring the IBM Technology Zone reservation The foundation for the on-premises environment utilizes the OpenShift Cluster (VMware on IBM Cloud) - UPI - Public template from the collection of IBM Technolgy Zone (ITZ) Certified Base Images . Click the link below to request a reservation directly from ITZ: URL: https://techzone.ibm.com/my/reservations/create/63a3a25a3a4689001740dbb3 From the Single environment reservation options , select Reserve now [A] . Supply additional details about the ITZ reservation request: RESERVATON POLICY NOTICE After selecting Education for the Purpose field, you may receive a pop-up notification stating that this environment is now being redirected to the OCPv base image hosted On-Prem for Education and Test . You can safely ignore this notice and close it by clicking the X in the top-right corner. Do not configure using the Poughkeepsie-based resource that the notice attempts to redirect you to \u2014 it will not allow you to configure the necessary hardware specifications. Continue with the ITZ reservation request form as detailed below. If the pop-up appears again later in the configuration steps, continue to disregard the notice. Field Value Name Give your reservation a unique name. Purpose Education Purpose Description Give your reservation a unique description. Preferred Geography Select the region and data center geographically closest to your location. End Date and Time Select a time and date for when the reservation will expire. OpenShift Version 4.16 Worker Node Count 3 Worker Node Flavor 32 vCPU x 128 GB - 300 GB ephemeral storage Storage ODF - 2 TB OCP/Kubernetes Cluster Network 10.128.0.0/14 OCP/Kubernetes Service Network 172.30.0.0/16 Enable nested hardware virtualization on workers No When satisfied, verify that you agree to the Terms and Conditions for the environment and finalize your reservation request by clicking Submit . PROVISIONING TIMES Cluster provisioning and deployment takes approximately 90 to 120 minutes to complete from the time that you click submit. Navigate to the My Reservations tab of the ITZ to monitor the progress of your reservation. Wait for the ITZ reservation to be marked as \"Ready\" before attempting to start the lab. ii. Accessing the cluster Once the cluster has been successfully deployed, you will receive an email with the header: Reservation Ready on IBM Technology Zone . Confirm that the ITZ email states that Status Update: Ready [A] . Follow the link provided in the email, or access the My Reservations tab on ITZ to access your reservation. Record the following connection details variables for the OpenShift Container Platform (OCP) cluster to a notepad: Username Password Click the blue Open your IBM Cloud environment button at the top of the page to launch a new browser window for accessing the OCP cluster. Choose the kube:admin log in option and then provide the following credentials: Username: kubeadmin Password: password recorded in Step 6 At this stage, you should have successfully logged in to the OCP dashboard. After logging into the OCP dashboard, copy the URL of the page (from your web browser) and record that to a notepad as OCP dashboard URL . This will be referenced in subsequent modules. iii. Next steps In the following module, you will access and configure the cluster's bastion node.","title":"2. Reserve an environment"},{"location":"on-premises/2/#reserve-an-environmenton-premises-installation-and-deployment","text":"If you require assistance or run into issues with the hands-on lab, help is available. Environment issues: The lab environment is managed by IBM Technology Zone. Opening a support case ticket is recommended for issues related to the hands-on environment (provisioning, running, and so on.) Documentation issues: If there is an error in the lab documentation, or if you require additional support in completing the material, open a thread on the #wca-ansible-techzone-support Slack channel.","title":"Reserve an EnvironmentOn-Premises Installation and Deployment"},{"location":"on-premises/2/#i-configuring-the-ibm-technology-zone-reservation","text":"The foundation for the on-premises environment utilizes the OpenShift Cluster (VMware on IBM Cloud) - UPI - Public template from the collection of IBM Technolgy Zone (ITZ) Certified Base Images . Click the link below to request a reservation directly from ITZ: URL: https://techzone.ibm.com/my/reservations/create/63a3a25a3a4689001740dbb3 From the Single environment reservation options , select Reserve now [A] . Supply additional details about the ITZ reservation request: RESERVATON POLICY NOTICE After selecting Education for the Purpose field, you may receive a pop-up notification stating that this environment is now being redirected to the OCPv base image hosted On-Prem for Education and Test . You can safely ignore this notice and close it by clicking the X in the top-right corner. Do not configure using the Poughkeepsie-based resource that the notice attempts to redirect you to \u2014 it will not allow you to configure the necessary hardware specifications. Continue with the ITZ reservation request form as detailed below. If the pop-up appears again later in the configuration steps, continue to disregard the notice. Field Value Name Give your reservation a unique name. Purpose Education Purpose Description Give your reservation a unique description. Preferred Geography Select the region and data center geographically closest to your location. End Date and Time Select a time and date for when the reservation will expire. OpenShift Version 4.16 Worker Node Count 3 Worker Node Flavor 32 vCPU x 128 GB - 300 GB ephemeral storage Storage ODF - 2 TB OCP/Kubernetes Cluster Network 10.128.0.0/14 OCP/Kubernetes Service Network 172.30.0.0/16 Enable nested hardware virtualization on workers No When satisfied, verify that you agree to the Terms and Conditions for the environment and finalize your reservation request by clicking Submit . PROVISIONING TIMES Cluster provisioning and deployment takes approximately 90 to 120 minutes to complete from the time that you click submit. Navigate to the My Reservations tab of the ITZ to monitor the progress of your reservation. Wait for the ITZ reservation to be marked as \"Ready\" before attempting to start the lab.","title":"i. Configuring the IBM Technology Zone reservation"},{"location":"on-premises/2/#ii-accessing-the-cluster","text":"Once the cluster has been successfully deployed, you will receive an email with the header: Reservation Ready on IBM Technology Zone . Confirm that the ITZ email states that Status Update: Ready [A] . Follow the link provided in the email, or access the My Reservations tab on ITZ to access your reservation. Record the following connection details variables for the OpenShift Container Platform (OCP) cluster to a notepad: Username Password Click the blue Open your IBM Cloud environment button at the top of the page to launch a new browser window for accessing the OCP cluster. Choose the kube:admin log in option and then provide the following credentials: Username: kubeadmin Password: password recorded in Step 6 At this stage, you should have successfully logged in to the OCP dashboard. After logging into the OCP dashboard, copy the URL of the page (from your web browser) and record that to a notepad as OCP dashboard URL . This will be referenced in subsequent modules.","title":"ii. Accessing the cluster"},{"location":"on-premises/2/#iii-next-steps","text":"In the following module, you will access and configure the cluster's bastion node.","title":"iii. Next steps"},{"location":"on-premises/3/","text":"Bastion Host Setup On-Premises Installation and Deployment The following section is based off of IBM Documentation write-ups that detail how to install IBM Software Hub on a Red Hat OpenShift Container Platform cluster. Reference the instructions in full at the following resource: Installing the IBM Software Hub command-line interface . i. Connect to the bastion host Before configuring the bastion host node, you will need to retrieve its connectivity and access control details. Return to the My Reservations page on the IBM Technology Zone (ITZ) and open the dashboard for the OpenShift Container Platform (OCP) cluster. Scroll down to the bottom of the summary page and locate the following key-value pairs related to the bastion host node. Copy these to a notepad for reference later: Bastion Password Bastion RDP Address Bastion SSH Connection Bastion Username There are also key-value pairs related to the OCP cluster that, for convenience, you should also record at this time \u2014 they will be used in later parts of the lab: Cluster Admin Username Cluster Admin Password OCP Console Open a Terminal (Windows Terminal or the Terminal built into VS Code are good alternatives if you're on a PC). Copy the Bastion SSH Connection recorded in Step 2 and paste it into the terminal console. Hit Enter to execute and create an SSH connection to the bastion host. When prompted Are you sure you want to continue connecting (yes/no/fingerprint)? , enter yes and hit Enter to proceed. The console will return a Welcome to IBM Technology Zone once connected to the bastion host, at which point you must authenticate. Authenticate when prompted to do so by providing the Bastion Password recorded in Step 2. If the console now reads [itzuser@localhost ~]$ then you have successfully accessed the bastion host. ii. OpenShift CLI Next, install the OpenShift Command Line Interface (CLI) to programmatically perform work with the bastion node. Retrieve the OCP dashboard URL (recorded in Step 8 of the previous module). Obtain the OpenShift base domain by extracting the portion of the URL that matches the position highlighted in the sample URL below. Extract the portion after .apps. until the end of the URL. The characters in your OCP dashboard URL will differ. https://console-openshift-console.apps. 678a250b79141644e78804e0.ocp.techzone.ibm.com In this example, the value of the OpenShift base domain is 678a250b79141644e78804e0.ocp.techzone.ibm.com Record your OCP cluster's value to a notepad for future reference. The following instruction set, when executed within a Terminal window, will install the OpenShift CLI on the bastion host node. However, the instructions require some modification before they will successfully execute. Install OpenShift CLI export OPENSHIFT_BASE_DOMAIN = <CHANGE_ME> wget --no-check-certificate https://downloads-openshift-console.apps. ${ OPENSHIFT_BASE_DOMAIN } /amd64/linux/oc.tar tar -xvf oc.tar chmod +x oc sudo mv oc /usr/local/bin/oc Copy the instructions above and paste into a notepad. Replace the highlighted <CHANGE_ME> text with the OpenShift base domain value recorded in Step 4. Copy the modified notepad instructions to your clipboard and paste into your Terminal console. Press Enter to execute the instructions. The installation should only take a few minutes to complete. Once finished, try typing oc into the console window and hit Enter . The console output should verify that oc (the OpenShift CLI) has been successfully installed on the bastion host. iii. Podman install IBM Cloud Pak for Data (CP4D)'s installer requires containers and as such Podman must be set up on the bastion host ahead of time. Using the connected Terminal console, execute the following instruction to install Podman: sudo yum install -y podman The process will take approximately 1 minute to complete. iv. Environment variables Next, you must set the environment variables needed for installation of CP4D on the cluster. The list is quite extensive and long, so rather than set these one at a time it's recommended that you first compile them into a single file on the bastion host. Afterwards you can set all the variables automatically using the single file. Below is a code block containing all of the necessary CP4D environment variables. Copy the contents of the entire block to your clipboard. With your Terminal console, execute the following instruction to open the vi editor and create a shell script named cpd_vars.sh on the bastion host: vi cpd_vars.sh With the VI editor now open, press the I key to enable inserting text. Press Cmd + V (or Ctrl + V ) to paste the contents from your clipboard. To save, press Esc and then type :wq followed by Enter to write and exit. CP4D Environment Variables #=============================================================================== # Cloud Pak for Data installation variables #=============================================================================== #------------------------------------------------------------------------------ # Client workstation #------------------------------------------------------------------------------ # Set the following variables if you want to override the default behaviorof the Cloud Pak for Data CLI. # # To export these variables, you must uncomment each command in this sec-tion. #export CPD_CLI_MANAGE_WORKSPACE=<enter a fully qualified directory> # following lines could be used for environment with self-signed certificates and hostnames not resolved by DNS server #export OLM_UTILS_LAUNCH_ARGS=\"-v ./api-wxai.pem:/etc/k8scert --env K8S_AUTH_SSL_CA_CERT=/etc/k8scert --add-host oauth-openshift.apps.ocpinstall.gym.lan:192.168.252.4 --add-host api.ocpinstall.gym.lan:192.168.252.3\" export PATH = \"/home/itzuser/cpd-cli-linux-EE-14.1.0-1189\" : $PATH #----------------------------------------------------------------------------- # Cluster #------------------------------------------------------------------------------ export OCP_URL = api.ocpinstall.gym.lan:6443 #export OPENSHIFT_TYPE=<enter your deployment type> #export IMAGE_ARCH=amd64 export OCP_USERNAME = kubeadmin export OCP_PASSWORD = mcnfM-MdnmC-y6ZES-cAKjj # export OCP_TOKEN=<enter your token> export SERVER_ARGUMENTS = \"--server= ${ OCP_URL } \" export LOGIN_ARGUMENTS = \"--username= ${ OCP_USERNAME } --password= ${ OCP_PASSWORD } \" # export LOGIN_ARGUMENTS=\"--token=${OCP_TOKEN}\" export CPDM_OC_LOGIN = \"cpd-cli manage login-to-ocp ${ SERVER_ARGUMENTS } ${ LOGIN_ARGUMENTS } \" export OC_LOGIN = \"oc login ${ OCP_URL } ${ LOGIN_ARGUMENTS } \" #------------------------------------------------------------------------------ # Projects #------------------------------------------------------------------------------ export PROJECT_LICENSE_SERVICE = cpd-license export PROJECT_SCHEDULING_SERVICE = cpd-scheduling export PROJECT_CPD_INST_OPERATORS = cpd-operators export PROJECT_CPD_INST_OPERANDS = cpd-watsonx # export PROJECT_CPD_INSTANCE_TETHERED=<enter your tethered project> # export PROJECT_CPD_INSTANCE_TETHERED_LIST=<a comma-separated list of teth-ered projects> #------------------------------------------------------------------------------ # Storage #------------------------------------------------------------------------------ export STG_CLASS_BLOCK = ocs-storagecluster-ceph-rbd export STG_CLASS_FILE = ocs-storagecluster-cephfs #------------------------------------------------------------------------------ # IBM Entitled Registry #------------------------------------------------------------------------------ export IBM_ENTITLEMENT_KEY = XXX.eyJpc3MiOiJJQk0gTWFya2V0cGxhY2UiLCJpYXQiOjE3MDU5MzkzNzcsImp0aSI6IjVjM2EzMzQ1MzdlNTQ5ZWE5MzRmNGZmYzNmYzc5MWNjIn0.Xa0C23QmwCsOR9whmf8OkiId--SXVZ4pxw6lrIvvb_M #------------------------------------------------------------------------------ # Cloud Pak for Data version #------------------------------------------------------------------------------ export VERSION = 5 .1.0 #------------------------------------------------------------------------------ # Components #------------------------------------------------------------------------------ #export COMPONENTS=ibm-cert-manager,ibm-licensing,scheduler,cpfs,cpd_plat-form # export COMPONENTS_TO_SKIP=<component-ID-1>,<component-ID-2> #export COMPONENTS=ibm-cert-manager,ibm-licensing,cpfs,scheduler,cpd_plat-form,wml,ws,watsonx_ai export COMPONENTS = cpd_platform,watsonx_ai v. Cloud Pak for Data command line interface (cpd-cli) Now that the environment variables have been set, the next step towards installing CP4D is preparing the command line interface ( cpd-cli ). First, execute the following command in the Terminal console so that subsequent actions taken are done with elevated permissions: ``` shell sudo bash ``` Then copy the following code block and execute within the console to install cpd-cli . Installation should only take a few moments to complete. ``` shell wget https://github.com/IBM/cpd-cli/releases/download/v14.1.0/cpd-cli-linux-EE-14.1.0.tgz tar -xzf cpd-cli-linux-EE-14.1.0.tgz export PATH=\"$(pwd)/cpd-cli-linux-EE-14.1.0-1189\":$PATH ``` Verify that the CLI has been successfully integrated by typing cpd-cli and then Enter into the console. Engage the command line interface and ensure that the Terminal console is executing all subsequent instructions with full (root) privileges: echo $PATH cpd-cli manage restart-container This step will take a minute or two before completing. Once it has completed, you can verify the status of the restarted container by typing podman ps and Enter , which should return the result of a single container running on the bastion host. vi. Nest steps At this stage the bastion host node has been fully configured ahead of installing the necessary software, which will be covered in the subsequent modules. SESSION TIMEOUTS AND LOGGING BACK IN Be aware that SSH connections made over Terminal will time out after a long period of inactivity or due to a connection error. If you need to log back into the bastion terminal, follow the procedure below. Replace the <...> placeholders with values specific to your environment. Log back into the bastion node: ssh itzuser@api.67828ca5e432cac47ccc4230.ocp.techzone.ibm.com -p 40222 <BASTION_PWD> Engage the sudo (privileged access) session: sudo bash Source the environment variables stored in cpd_vars.sh : source cpd_vars.sh Log back into OpenShift: ${ OC_LOGIN } Log back into cpd-cli : ${ CPDM_OC_LOGIN }","title":"3. Bastion host setup"},{"location":"on-premises/3/#bastion-host-setupon-premises-installation-and-deployment","text":"The following section is based off of IBM Documentation write-ups that detail how to install IBM Software Hub on a Red Hat OpenShift Container Platform cluster. Reference the instructions in full at the following resource: Installing the IBM Software Hub command-line interface .","title":"Bastion Host SetupOn-Premises Installation and Deployment"},{"location":"on-premises/3/#i-connect-to-the-bastion-host","text":"Before configuring the bastion host node, you will need to retrieve its connectivity and access control details. Return to the My Reservations page on the IBM Technology Zone (ITZ) and open the dashboard for the OpenShift Container Platform (OCP) cluster. Scroll down to the bottom of the summary page and locate the following key-value pairs related to the bastion host node. Copy these to a notepad for reference later: Bastion Password Bastion RDP Address Bastion SSH Connection Bastion Username There are also key-value pairs related to the OCP cluster that, for convenience, you should also record at this time \u2014 they will be used in later parts of the lab: Cluster Admin Username Cluster Admin Password OCP Console Open a Terminal (Windows Terminal or the Terminal built into VS Code are good alternatives if you're on a PC). Copy the Bastion SSH Connection recorded in Step 2 and paste it into the terminal console. Hit Enter to execute and create an SSH connection to the bastion host. When prompted Are you sure you want to continue connecting (yes/no/fingerprint)? , enter yes and hit Enter to proceed. The console will return a Welcome to IBM Technology Zone once connected to the bastion host, at which point you must authenticate. Authenticate when prompted to do so by providing the Bastion Password recorded in Step 2. If the console now reads [itzuser@localhost ~]$ then you have successfully accessed the bastion host.","title":"i. Connect to the bastion host"},{"location":"on-premises/3/#ii-openshift-cli","text":"Next, install the OpenShift Command Line Interface (CLI) to programmatically perform work with the bastion node. Retrieve the OCP dashboard URL (recorded in Step 8 of the previous module). Obtain the OpenShift base domain by extracting the portion of the URL that matches the position highlighted in the sample URL below. Extract the portion after .apps. until the end of the URL. The characters in your OCP dashboard URL will differ. https://console-openshift-console.apps. 678a250b79141644e78804e0.ocp.techzone.ibm.com In this example, the value of the OpenShift base domain is 678a250b79141644e78804e0.ocp.techzone.ibm.com Record your OCP cluster's value to a notepad for future reference. The following instruction set, when executed within a Terminal window, will install the OpenShift CLI on the bastion host node. However, the instructions require some modification before they will successfully execute. Install OpenShift CLI export OPENSHIFT_BASE_DOMAIN = <CHANGE_ME> wget --no-check-certificate https://downloads-openshift-console.apps. ${ OPENSHIFT_BASE_DOMAIN } /amd64/linux/oc.tar tar -xvf oc.tar chmod +x oc sudo mv oc /usr/local/bin/oc Copy the instructions above and paste into a notepad. Replace the highlighted <CHANGE_ME> text with the OpenShift base domain value recorded in Step 4. Copy the modified notepad instructions to your clipboard and paste into your Terminal console. Press Enter to execute the instructions. The installation should only take a few minutes to complete. Once finished, try typing oc into the console window and hit Enter . The console output should verify that oc (the OpenShift CLI) has been successfully installed on the bastion host.","title":"ii. OpenShift CLI"},{"location":"on-premises/3/#iii-podman-install","text":"IBM Cloud Pak for Data (CP4D)'s installer requires containers and as such Podman must be set up on the bastion host ahead of time. Using the connected Terminal console, execute the following instruction to install Podman: sudo yum install -y podman The process will take approximately 1 minute to complete.","title":"iii. Podman install"},{"location":"on-premises/3/#iv-environment-variables","text":"Next, you must set the environment variables needed for installation of CP4D on the cluster. The list is quite extensive and long, so rather than set these one at a time it's recommended that you first compile them into a single file on the bastion host. Afterwards you can set all the variables automatically using the single file. Below is a code block containing all of the necessary CP4D environment variables. Copy the contents of the entire block to your clipboard. With your Terminal console, execute the following instruction to open the vi editor and create a shell script named cpd_vars.sh on the bastion host: vi cpd_vars.sh With the VI editor now open, press the I key to enable inserting text. Press Cmd + V (or Ctrl + V ) to paste the contents from your clipboard. To save, press Esc and then type :wq followed by Enter to write and exit. CP4D Environment Variables #=============================================================================== # Cloud Pak for Data installation variables #=============================================================================== #------------------------------------------------------------------------------ # Client workstation #------------------------------------------------------------------------------ # Set the following variables if you want to override the default behaviorof the Cloud Pak for Data CLI. # # To export these variables, you must uncomment each command in this sec-tion. #export CPD_CLI_MANAGE_WORKSPACE=<enter a fully qualified directory> # following lines could be used for environment with self-signed certificates and hostnames not resolved by DNS server #export OLM_UTILS_LAUNCH_ARGS=\"-v ./api-wxai.pem:/etc/k8scert --env K8S_AUTH_SSL_CA_CERT=/etc/k8scert --add-host oauth-openshift.apps.ocpinstall.gym.lan:192.168.252.4 --add-host api.ocpinstall.gym.lan:192.168.252.3\" export PATH = \"/home/itzuser/cpd-cli-linux-EE-14.1.0-1189\" : $PATH #----------------------------------------------------------------------------- # Cluster #------------------------------------------------------------------------------ export OCP_URL = api.ocpinstall.gym.lan:6443 #export OPENSHIFT_TYPE=<enter your deployment type> #export IMAGE_ARCH=amd64 export OCP_USERNAME = kubeadmin export OCP_PASSWORD = mcnfM-MdnmC-y6ZES-cAKjj # export OCP_TOKEN=<enter your token> export SERVER_ARGUMENTS = \"--server= ${ OCP_URL } \" export LOGIN_ARGUMENTS = \"--username= ${ OCP_USERNAME } --password= ${ OCP_PASSWORD } \" # export LOGIN_ARGUMENTS=\"--token=${OCP_TOKEN}\" export CPDM_OC_LOGIN = \"cpd-cli manage login-to-ocp ${ SERVER_ARGUMENTS } ${ LOGIN_ARGUMENTS } \" export OC_LOGIN = \"oc login ${ OCP_URL } ${ LOGIN_ARGUMENTS } \" #------------------------------------------------------------------------------ # Projects #------------------------------------------------------------------------------ export PROJECT_LICENSE_SERVICE = cpd-license export PROJECT_SCHEDULING_SERVICE = cpd-scheduling export PROJECT_CPD_INST_OPERATORS = cpd-operators export PROJECT_CPD_INST_OPERANDS = cpd-watsonx # export PROJECT_CPD_INSTANCE_TETHERED=<enter your tethered project> # export PROJECT_CPD_INSTANCE_TETHERED_LIST=<a comma-separated list of teth-ered projects> #------------------------------------------------------------------------------ # Storage #------------------------------------------------------------------------------ export STG_CLASS_BLOCK = ocs-storagecluster-ceph-rbd export STG_CLASS_FILE = ocs-storagecluster-cephfs #------------------------------------------------------------------------------ # IBM Entitled Registry #------------------------------------------------------------------------------ export IBM_ENTITLEMENT_KEY = XXX.eyJpc3MiOiJJQk0gTWFya2V0cGxhY2UiLCJpYXQiOjE3MDU5MzkzNzcsImp0aSI6IjVjM2EzMzQ1MzdlNTQ5ZWE5MzRmNGZmYzNmYzc5MWNjIn0.Xa0C23QmwCsOR9whmf8OkiId--SXVZ4pxw6lrIvvb_M #------------------------------------------------------------------------------ # Cloud Pak for Data version #------------------------------------------------------------------------------ export VERSION = 5 .1.0 #------------------------------------------------------------------------------ # Components #------------------------------------------------------------------------------ #export COMPONENTS=ibm-cert-manager,ibm-licensing,scheduler,cpfs,cpd_plat-form # export COMPONENTS_TO_SKIP=<component-ID-1>,<component-ID-2> #export COMPONENTS=ibm-cert-manager,ibm-licensing,cpfs,scheduler,cpd_plat-form,wml,ws,watsonx_ai export COMPONENTS = cpd_platform,watsonx_ai","title":"iv. Environment variables"},{"location":"on-premises/3/#v-cloud-pak-for-data-command-line-interface-cpd-cli","text":"Now that the environment variables have been set, the next step towards installing CP4D is preparing the command line interface ( cpd-cli ). First, execute the following command in the Terminal console so that subsequent actions taken are done with elevated permissions: ``` shell sudo bash ``` Then copy the following code block and execute within the console to install cpd-cli . Installation should only take a few moments to complete. ``` shell wget https://github.com/IBM/cpd-cli/releases/download/v14.1.0/cpd-cli-linux-EE-14.1.0.tgz tar -xzf cpd-cli-linux-EE-14.1.0.tgz export PATH=\"$(pwd)/cpd-cli-linux-EE-14.1.0-1189\":$PATH ``` Verify that the CLI has been successfully integrated by typing cpd-cli and then Enter into the console. Engage the command line interface and ensure that the Terminal console is executing all subsequent instructions with full (root) privileges: echo $PATH cpd-cli manage restart-container This step will take a minute or two before completing. Once it has completed, you can verify the status of the restarted container by typing podman ps and Enter , which should return the result of a single container running on the bastion host.","title":"v. Cloud Pak for Data command line interface (cpd-cli)"},{"location":"on-premises/3/#vi-nest-steps","text":"At this stage the bastion host node has been fully configured ahead of installing the necessary software, which will be covered in the subsequent modules. SESSION TIMEOUTS AND LOGGING BACK IN Be aware that SSH connections made over Terminal will time out after a long period of inactivity or due to a connection error. If you need to log back into the bastion terminal, follow the procedure below. Replace the <...> placeholders with values specific to your environment. Log back into the bastion node: ssh itzuser@api.67828ca5e432cac47ccc4230.ocp.techzone.ibm.com -p 40222 <BASTION_PWD> Engage the sudo (privileged access) session: sudo bash Source the environment variables stored in cpd_vars.sh : source cpd_vars.sh Log back into OpenShift: ${ OC_LOGIN } Log back into cpd-cli : ${ CPDM_OC_LOGIN }","title":"vi. Nest steps"},{"location":"on-premises/4/","text":"Cluster Preparation On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"4. Cluster preparation"},{"location":"on-premises/4/#cluster-preparationon-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"Cluster PreparationOn-Premises Installation and Deployment"},{"location":"on-premises/4/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/4/#ii-part-2","text":"test","title":"ii. Part 2"},{"location":"on-premises/5/","text":"Install Prerequisite Software On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"5. Install prerequisite software"},{"location":"on-premises/5/#install-prerequisite-softwareon-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"Install Prerequisite SoftwareOn-Premises Installation and Deployment"},{"location":"on-premises/5/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/5/#ii-part-2","text":"test","title":"ii. Part 2"},{"location":"on-premises/6/","text":"Install Shared Components On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"6. Install shared components"},{"location":"on-premises/6/#install-shared-componentson-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"Install Shared ComponentsOn-Premises Installation and Deployment"},{"location":"on-premises/6/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/6/#ii-part-2","text":"test","title":"ii. Part 2"},{"location":"on-premises/7/","text":"Install IBM Software Hub On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"7. Install IBM Software Hub"},{"location":"on-premises/7/#install-ibm-software-hubon-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"Install IBM Software HubOn-Premises Installation and Deployment"},{"location":"on-premises/7/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/7/#ii-part-2","text":"test","title":"ii. Part 2"},{"location":"on-premises/8/","text":"Install IBM watsonx Code Assistant On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"8. Install watsonx Code Assistant"},{"location":"on-premises/8/#install-ibm-watsonx-code-assistanton-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"Install IBM watsonx Code AssistantOn-Premises Installation and Deployment"},{"location":"on-premises/8/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/8/#ii-part-2","text":"test","title":"ii. Part 2"},{"location":"on-premises/9/","text":"Conclusion On-Premises Installation and Deployment Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min] i. Part 1 And ii. Part 2 test","title":"9. Conclusion"},{"location":"on-premises/9/#conclusionon-premises-installation-and-deployment","text":"Christopher Bienko (Principal, IBM Global Sales Enablement) demonstrates key elements and hands-on components of the Generating Code module. [10 min]","title":"ConclusionOn-Premises Installation and Deployment"},{"location":"on-premises/9/#i-part-1","text":"And","title":"i. Part 1"},{"location":"on-premises/9/#ii-part-2","text":"test","title":"ii. Part 2"}]}